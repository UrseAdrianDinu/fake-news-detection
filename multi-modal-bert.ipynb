{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from transformers import BertModel, BertTokenizer, AutoTokenizer, AdamW\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "import functools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "\n",
    "import contextlib\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "model_id = \"dumitrescustefan/bert-base-romanian-cased-v1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.args = args\n",
    "        model = torchvision.models.resnet152(weights='ResNet152_Weights.DEFAULT')\n",
    "        modules = list(model.children())[:-2]\n",
    "        self.model = nn.Sequential(*modules)\n",
    "\n",
    "        pool_func = (nn.AdaptiveAvgPool2d)\n",
    "\n",
    "        # if args.num_image_embeds in [1, 2, 3, 5, 7]:\n",
    "        # self.pool = pool_func((args.num_image_embeds, 1))\n",
    "        self.pool = pool_func((1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Bx3x224x224 -> Bx2048x7x7 -> Bx2048xN -> BxNx2048\n",
    "        out = self.pool(self.model(x))\n",
    "        out = torch.flatten(out, start_dim=2)\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        return out  # BxNx2048\n",
    "\n",
    "\n",
    "class ImageClf(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(ImageClf, self).__init__()\n",
    "        self.args = args\n",
    "        self.img_encoder = ImageEncoder(args)\n",
    "        self.clf = nn.Linear(2048 * 1, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.img_encoder(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        out = self.clf(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBertEmbeddings(nn.Module):\n",
    "    def __init__(self, args, embeddings, vocab):\n",
    "        super(ImageBertEmbeddings, self).__init__()\n",
    "        self.args = args\n",
    "        self.vocab = vocab\n",
    "        self.img_embeddings = nn.Linear(2048, 768)\n",
    "        self.position_embeddings = embeddings.position_embeddings\n",
    "        self.token_type_embeddings = embeddings.token_type_embeddings\n",
    "        self.word_embeddings = embeddings.word_embeddings\n",
    "        self.LayerNorm = embeddings.LayerNorm\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, input_imgs, token_type_ids):\n",
    "        bsz = input_imgs.size(0)\n",
    "        seq_length = 1 + 2  # +2 for CLS and SEP Token\n",
    "\n",
    "        cls_id = torch.LongTensor([self.vocab.stoi[\"[CLS]\"]]).cuda()\n",
    "        cls_id = cls_id.unsqueeze(0).expand(bsz, 1)\n",
    "        cls_token_embeds = self.word_embeddings(cls_id)\n",
    "\n",
    "        sep_id = torch.LongTensor([self.vocab.stoi[\"[SEP]\"]]).cuda()\n",
    "        sep_id = sep_id.unsqueeze(0).expand(bsz, 1)\n",
    "        sep_token_embeds = self.word_embeddings(sep_id)\n",
    "\n",
    "        imgs_embeddings = self.img_embeddings(input_imgs)\n",
    "        token_embeddings = torch.cat(\n",
    "            [cls_token_embeds, imgs_embeddings, sep_token_embeds], dim=1\n",
    "        )\n",
    "\n",
    "        position_ids = torch.arange(seq_length, dtype=torch.long).cuda()\n",
    "        position_ids = position_ids.unsqueeze(0).expand(bsz, seq_length)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n",
    "        embeddings = token_embeddings + position_embeddings + token_type_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class MultimodalBertEncoder(nn.Module):\n",
    "    def __init__(self, args, vocab):\n",
    "        super(MultimodalBertEncoder, self).__init__()\n",
    "        self.args = args\n",
    "        self.vocab = vocab\n",
    "        bert = BertModel.from_pretrained(model_id)\n",
    "        self.txt_embeddings = bert.embeddings\n",
    "\n",
    "        self.img_embeddings = ImageBertEmbeddings(args, self.txt_embeddings, vocab)\n",
    "        self.img_encoder = ImageEncoder(args)\n",
    "        self.encoder = bert.encoder\n",
    "        self.pooler = bert.pooler\n",
    "        self.clf = nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_txt, attention_mask, segment, input_img):\n",
    "        bsz = input_txt.size(0)\n",
    "        attention_mask = torch.cat(\n",
    "            [\n",
    "                torch.ones(bsz, 1 + 2).long().cuda(),\n",
    "                attention_mask,\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "        extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        extended_attention_mask = extended_attention_mask.to(\n",
    "            dtype=next(self.parameters()).dtype\n",
    "        )\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        img_tok = (\n",
    "            torch.LongTensor(input_txt.size(0), 1 + 2)\n",
    "            .fill_(0)\n",
    "            .cuda()\n",
    "        )\n",
    "        img = self.img_encoder(input_img)  # BxNx3x224x224 -> BxNx2048\n",
    "        img_embed_out = self.img_embeddings(img, img_tok)\n",
    "        txt_embed_out = self.txt_embeddings(input_txt, segment)\n",
    "        encoder_input = torch.cat([img_embed_out, txt_embed_out], 1)  # Bx(TEXT+IMG)xHID\n",
    "\n",
    "        encoded_layers = self.encoder(\n",
    "            encoder_input, extended_attention_mask\n",
    "        )\n",
    "\n",
    "        return self.pooler(encoded_layers[-1])\n",
    "\n",
    "\n",
    "class MultimodalBertClf(nn.Module):\n",
    "    def __init__(self, args, vocab):\n",
    "        super(MultimodalBertClf, self).__init__()\n",
    "        self.args = args\n",
    "        self.vocab = vocab\n",
    "        self.enc = MultimodalBertEncoder(args, self.vocab)\n",
    "        self.clf = nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, txt, mask, segment, img):\n",
    "        x = self.enc(txt, mask, segment, img)\n",
    "        return self.clf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to train_stiri_text_mapping_image.json\n",
      "DataFrame has been saved to test_stiri_text_mapping_image.json\n"
     ]
    }
   ],
   "source": [
    " # Definirea listelor pentru a stoca datele\n",
    "folders = ['stiri_fabricate', 'stiri_plauzibile', 'stiri_propagandistice', 'stiri_reale', 'stiri_satirice']\n",
    "image_folders = [folder + '_img' for folder in folders]\n",
    "data = {'img_path': [], 'Text': [], 'Label': []}\n",
    " \n",
    "\n",
    "image_dir = r'C:\\Users\\bebed\\OneDrive\\Desktop\\Dizertatie\\dataset\\images'\n",
    "root_dir = r'C:\\Users\\bebed\\OneDrive\\Desktop\\Dizertatie\\dataset'\n",
    "\n",
    "classes = sorted(os.listdir(image_dir))\n",
    "file_paths = []\n",
    "labels = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    class_path = os.path.join(image_dir, class_name)\n",
    "    filenames = os.listdir(class_path)\n",
    "    dir_name = \"stiri_\" + class_name\n",
    "    text_dir = os.path.join(root_dir, dir_name)   \n",
    "    for filename in filenames:\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            data['img_path'].append(img_path)\n",
    "            data['Label'].append(class_name)\n",
    "            image_name_no_ext, _ = os.path.splitext(filename)\n",
    "            text_file_path = os.path.join(text_dir, f'{image_name_no_ext}.txt')\n",
    "            if os.path.exists(text_file_path):\n",
    "                with open(text_file_path, 'r', encoding='utf-8') as file:\n",
    "                    text_data = file.read()\n",
    "                data['Text'].append(text_data)\n",
    "\n",
    "# print(len(data[\"Text\"]))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # Afișăm DataFrame-ul\n",
    "# print(df)\n",
    " \n",
    "train_json_filename = 'train_stiri_text_mapping_image.json'\n",
    "test_json_filename = 'test_stiri_text_mapping_image.json'\n",
    "\n",
    "train_df.to_json(train_json_filename, orient='records', lines=True, force_ascii=False)\n",
    "test_df.to_json(test_json_filename, orient='records', lines=True, force_ascii=False)\n",
    "\n",
    "# # Print a message indicating the successful save\n",
    "print(f'DataFrame has been saved to {train_json_filename}')\n",
    "print(f'DataFrame has been saved to {test_json_filename}')\n",
    "\n",
    "json_filename = 'stiri_text_mapping_image.json'\n",
    "\n",
    "# Load the JSON data from the file\n",
    "data = []\n",
    "with open(json_filename, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        record = json.loads(line)\n",
    "        data.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_frequencies():\n",
    "    class_count = {}\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        filenames = os.listdir(class_path)\n",
    "        class_count[class_name] = len(filenames)\n",
    "    label_freqs = Counter(class_count)\n",
    "\n",
    "    return list(label_freqs.keys()), label_freqs\n",
    "\n",
    "\n",
    "class JsonlDataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, transforms, vocab, args):\n",
    "        self.data = self.get_data(data_path)\n",
    "        self.data_dir = os.path.dirname(data_path)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.args = args\n",
    "        self.classes = get_labels_and_frequencies()\n",
    "        self.vocab = vocab\n",
    "        self.n_classes = 5\n",
    "        self.text_start_token = [\"[SEP]\"]\n",
    "\n",
    "        self.max_seq_len = 512\n",
    "        self.max_seq_len -= 1\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def get_data(self, data_path):\n",
    "        data = []\n",
    "        with open(data_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                record = json.loads(line)\n",
    "                data.append(record)\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence = (\n",
    "            self.text_start_token\n",
    "            + self.tokenizer.tokenize(self.data[index][\"Text\"])[\n",
    "                : (512 - 1)\n",
    "            ]\n",
    "        )\n",
    "        segment = torch.zeros(len(sentence))\n",
    "\n",
    "        sentence = torch.LongTensor(\n",
    "            [\n",
    "                self.vocab.stoi[w] if w in self.vocab.stoi else self.vocab.stoi[\"[UNK]\"]\n",
    "                for w in sentence\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        label = torch.LongTensor(\n",
    "            [ self.classes[0].index(self.data[index][\"Label\"])]\n",
    "        )\n",
    "\n",
    "        image = None\n",
    "        if self.data[index][\"img_path\"]:\n",
    "            image = Image.open(self.data[index][\"img_path\"]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "\n",
    "        # The first SEP is part of Image Token.\n",
    "        segment = segment[1:]\n",
    "        sentence = sentence[1:]\n",
    "        # The first segment (0) is of images.\n",
    "        segment += 1\n",
    "        return sentence, segment, image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab(object):\n",
    "    def __init__(self, emptyInit=False):\n",
    "        if emptyInit:\n",
    "            self.stoi, self.itos, self.vocab_sz = {}, [], 0\n",
    "        else:\n",
    "            self.stoi = {\n",
    "                w: i\n",
    "                for i, w in enumerate([\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
    "            }\n",
    "            self.itos = [w for w in self.stoi]\n",
    "            self.vocab_sz = len(self.itos)\n",
    "\n",
    "    def add(self, words):\n",
    "        cnt = len(self.itos)\n",
    "        for w in words:\n",
    "            if w in self.stoi:\n",
    "                continue\n",
    "            self.stoi[w] = cnt\n",
    "            self.itos.append(w)\n",
    "            cnt += 1\n",
    "        self.vocab_sz = len(self.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms():\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
    "                std=[0.12221994, 0.12145835, 0.14380469],\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_vocab():\n",
    "    vocab = Vocab()\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(model_id)\n",
    "    vocab.stoi = bert_tokenizer.vocab\n",
    "    vocab.itos = bert_tokenizer.ids_to_tokens\n",
    "    vocab.vocab_sz = len(vocab.itos)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "def collate_fn(batch, args):\n",
    "    lens = [len(row[0]) for row in batch]\n",
    "    bsz, max_seq_len = len(batch), max(lens)\n",
    "\n",
    "    mask_tensor = torch.zeros(bsz, max_seq_len).long()\n",
    "    text_tensor = torch.zeros(bsz, max_seq_len).long()\n",
    "    segment_tensor = torch.zeros(bsz, max_seq_len).long()\n",
    "\n",
    "    img_tensor = None\n",
    "    img_tensor = torch.stack([row[2] for row in batch])\n",
    "\n",
    "    # Single Label case\n",
    "    tgt_tensor = torch.cat([row[3] for row in batch]).long()\n",
    "\n",
    "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
    "        tokens, segment = input_row[:2]\n",
    "        text_tensor[i_batch, :length] = tokens\n",
    "        segment_tensor[i_batch, :length] = segment\n",
    "        mask_tensor[i_batch, :length] = 1\n",
    "\n",
    "    return text_tensor, segment_tensor, mask_tensor, img_tensor, tgt_tensor\n",
    "\n",
    "def get_data_loaders(args):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_id)\n",
    "    transforms = get_transforms()\n",
    "\n",
    "    # args.labels, args.label_freqs = get_labels_and_frequencies()\n",
    "    vocab = get_vocab()\n",
    "    # args.vocab = vocab\n",
    "    # args.vocab_sz = vocab.vocab_sz\n",
    "    # args.n_classes = len(args.labels)\n",
    "\n",
    "    train_path = r'C:\\Users\\bebed\\OneDrive\\Desktop\\BigData\\project\\train_stiri_text_mapping_image.json'\n",
    "    test_path = r'C:\\Users\\bebed\\OneDrive\\Desktop\\BigData\\project\\train_stiri_text_mapping_image.json'\n",
    "\n",
    "    train = JsonlDataset(\n",
    "        train_path,\n",
    "        tokenizer,\n",
    "        transforms,\n",
    "        vocab,\n",
    "        args,\n",
    "    )\n",
    "\n",
    "    # args.train_data_len = len(train)\n",
    "\n",
    "    dev = JsonlDataset(\n",
    "        test_path,\n",
    "        tokenizer,\n",
    "        transforms,\n",
    "        vocab,\n",
    "        args,\n",
    "    )\n",
    "\n",
    "    collate = functools.partial(collate_fn, args=args)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train,\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        dev,\n",
    "        batch_size=2,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate,\n",
    "    )\n",
    "\n",
    "    test_set = JsonlDataset(\n",
    "        test_path,\n",
    "        tokenizer,\n",
    "        transforms,\n",
    "        vocab,\n",
    "        args,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set,\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        collate_fn=collate,\n",
    "    )\n",
    "\n",
    "\n",
    "    return train, train_loader, dev, val_loader, test_set, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion():\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion\n",
    "\n",
    "def get_optimizer(model):\n",
    "    total_steps = (\n",
    "        670\n",
    "        / 32\n",
    "        / 24\n",
    "        * 100\n",
    "    )\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\": 0.01},\n",
    "        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0,},\n",
    "    ]\n",
    "    optimizer = AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=1e-4,\n",
    "        no_deprecation_warning=True\n",
    "    )\n",
    "    return optimizer\n",
    "\n",
    "def get_scheduler(optimizer):\n",
    "    return optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \"max\", patience=2, verbose=True, factor=0.5\n",
    "    )\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogFormatter:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def format(self, record):\n",
    "        elapsed_seconds = round(record.created - self.start_time)\n",
    "\n",
    "        prefix = \"%s - %s - %s\" % (\n",
    "            record.levelname,\n",
    "            time.strftime(\"%x %X\"),\n",
    "            timedelta(seconds=elapsed_seconds),\n",
    "        )\n",
    "        message = record.getMessage()\n",
    "        message = message.replace(\"\\n\", \"\\n\" + \" \" * (len(prefix) + 3))\n",
    "        return \"%s - %s\" % (prefix, message)\n",
    "\n",
    "\n",
    "def create_logger(filepath, args):\n",
    "    # create log formatter\n",
    "    log_formatter = LogFormatter()\n",
    "\n",
    "    # create file handler and set level to debug\n",
    "    file_handler = logging.FileHandler(filepath, \"a\")\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    file_handler.setFormatter(log_formatter)\n",
    "\n",
    "    # create console handler and set level to info\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    console_handler.setFormatter(log_formatter)\n",
    "\n",
    "    # create logger and set level to debug\n",
    "    logger = logging.getLogger()\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    logger.propagate = False\n",
    "    logger.addHandler(file_handler)\n",
    "    logger.addHandler(console_handler)\n",
    "\n",
    "    # reset logger elapsed time\n",
    "    def reset_time():\n",
    "        log_formatter.start_time = time.time()\n",
    "\n",
    "    logger.reset_time = reset_time\n",
    "\n",
    "    logger.info(\n",
    "        \"\\n\".join(\n",
    "            \"%s: %s\" % (k, str(v))\n",
    "            for k, v in sorted(dict(vars(args)).items(), key=lambda x: x[0])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(i_epoch, model, criterion, batch):\n",
    "    txt, segment, mask, img, tgt = batch\n",
    "\n",
    "    freeze_img = i_epoch < 0\n",
    "    freeze_txt = i_epoch < 0\n",
    "\n",
    "    for param in model.enc.img_encoder.parameters():\n",
    "        param.requires_grad = not freeze_img\n",
    "    for param in model.enc.encoder.parameters():\n",
    "        param.requires_grad = not freeze_txt\n",
    "\n",
    "    txt, img = txt.cuda(), img.cuda()\n",
    "    mask, segment = mask.cuda(), segment.cuda()\n",
    "    out = model(txt, mask, segment, img)\n",
    "\n",
    "    tgt = tgt.cuda()\n",
    "    loss = criterion(out, tgt)\n",
    "    return loss, out, tgt\n",
    "\n",
    "\n",
    "def model_eval(i_epoch, data, model, criterion):\n",
    "    with torch.no_grad():\n",
    "        losses, preds, tgts = [], [], []\n",
    "        for batch in data:\n",
    "            loss, out, tgt = model_forward(i_epoch, model, criterion, batch)\n",
    "            losses.append(loss.item())\n",
    "            pred = torch.nn.functional.softmax(out, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
    "\n",
    "            preds.append(pred)\n",
    "            tgt = tgt.cpu().detach().numpy()\n",
    "            tgts.append(tgt)\n",
    "\n",
    "    metrics = {\"loss\": np.mean(losses)}\n",
    "    tgts = [l for sl in tgts for l in sl]\n",
    "    preds = [l for sl in preds for l in sl]\n",
    "    metrics[\"acc\"] = accuracy_score(tgts, preds)\n",
    "    metrics[\"macro_f1\"] = f1_score(tgts, preds, average=\"macro\")\n",
    "    metrics[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
    "    metrics[\"recall\"] = recall_score(tgts, preds, average='micro')\n",
    "    metrics[\"precision\"] = precision_score(tgts, preds, average = 'micro')\n",
    "    # if store_preds:\n",
    "    #     store_preds_to_disk(tgts, preds, args)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultimodalBertClf(\n",
       "  (enc): MultimodalBertEncoder(\n",
       "    (txt_embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (img_embeddings): ImageBertEmbeddings(\n",
       "      (img_embeddings): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (img_encoder): ImageEncoder(\n",
       "      (model): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (6): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (7): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (6): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (7): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (8): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (9): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (10): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (11): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (12): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (13): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (14): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (15): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (16): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (17): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (18): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (19): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (20): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (21): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (22): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (23): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (24): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (25): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (26): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (27): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (28): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (29): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (30): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (31): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (32): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (33): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (34): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (35): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "    (clf): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       "  (clf): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train, train_loader, dev, val_loader, test_set, test_loader = get_data_loaders([])\n",
    "\n",
    "vocab = get_vocab()\n",
    "model = MultimodalBertClf([], vocab)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_criterion()\n",
    "optimizer = get_optimizer(model)\n",
    "scheduler = get_scheduler(optimizer)\n",
    "\n",
    "set_seed(42)\n",
    "start_epoch, global_step, n_no_improve, best_metric = 0, 0, 0, -np.inf\n",
    "\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 67/168 [03:03<04:57,  2.95s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 55%|█████▌    | 93/168 [04:21<03:49,  3.07s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 168/168 [07:37<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0226\n",
      "Train: Loss: 0.41271 | Acc: 0.83731 | macro_f1 0.70835 | micro_f1 0.83731 | recall 0.83731 | precision 0.83731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.41358 | Acc: 0.83731 | macro_f1 0.70835 | micro_f1 0.83731 | recall 0.83731 | precision 0.83731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 30/168 [01:39<08:02,  3.50s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 88%|████████▊ | 148/168 [08:12<01:09,  3.46s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [09:19<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0168\n",
      "Train: Loss: 0.28993 | Acc: 0.88806 | macro_f1 0.83496 | micro_f1 0.88806 | recall 0.88806 | precision 0.88806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.29008 | Acc: 0.88806 | macro_f1 0.83496 | micro_f1 0.88806 | recall 0.88806 | precision 0.88806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 36/168 [02:02<08:21,  3.80s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 46%|████▋     | 78/168 [04:20<05:01,  3.35s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 168/168 [09:29<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0116\n",
      "Train: Loss: 0.21457 | Acc: 0.91940 | macro_f1 0.88557 | micro_f1 0.91940 | recall 0.91940 | precision 0.91940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.21416 | Acc: 0.91940 | macro_f1 0.88557 | micro_f1 0.91940 | recall 0.91940 | precision 0.91940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 20/168 [01:16<10:06,  4.10s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 27%|██▋       | 46/168 [02:49<07:24,  3.64s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [09:45<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0066\n",
      "Train: Loss: 0.11460 | Acc: 0.95075 | macro_f1 0.92632 | micro_f1 0.95075 | recall 0.95075 | precision 0.95075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.11451 | Acc: 0.95075 | macro_f1 0.92632 | micro_f1 0.95075 | recall 0.95075 | precision 0.95075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 75/168 [04:09<05:55,  3.83s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 56%|█████▌    | 94/168 [05:21<05:05,  4.13s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [08:58<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0046\n",
      "Train: Loss: 0.03718 | Acc: 0.99104 | macro_f1 0.98824 | micro_f1 0.99104 | recall 0.99104 | precision 0.99104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.03720 | Acc: 0.99104 | macro_f1 0.98824 | micro_f1 0.99104 | recall 0.99104 | precision 0.99104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 10/168 [00:28<07:35,  2.88s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 34%|███▍      | 57/168 [02:40<05:42,  3.08s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [07:54<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036\n",
      "Train: Loss: 0.04774 | Acc: 0.98657 | macro_f1 0.98272 | micro_f1 0.98657 | recall 0.98657 | precision 0.98657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.04773 | Acc: 0.98657 | macro_f1 0.98272 | micro_f1 0.98657 | recall 0.98657 | precision 0.98657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 64/168 [03:32<06:00,  3.46s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 87%|████████▋ | 146/168 [08:04<01:10,  3.21s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [09:10<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017\n",
      "Train: Loss: 0.01946 | Acc: 0.99552 | macro_f1 0.99432 | micro_f1 0.99552 | recall 0.99552 | precision 0.99552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.01943 | Acc: 0.99552 | macro_f1 0.99432 | micro_f1 0.99552 | recall 0.99552 | precision 0.99552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 15/168 [00:46<08:03,  3.16s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 18%|█▊        | 31/168 [01:36<06:21,  2.78s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 168/168 [09:00<00:00,  3.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0010\n",
      "Train: Loss: 0.01031 | Acc: 0.99701 | macro_f1 0.99582 | micro_f1 0.99701 | recall 0.99701 | precision 0.99701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.01031 | Acc: 0.99701 | macro_f1 0.99582 | micro_f1 0.99701 | recall 0.99701 | precision 0.99701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 71/168 [03:45<05:29,  3.40s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 93%|█████████▎| 157/168 [08:22<00:33,  3.03s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [08:55<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0004\n",
      "Train: Loss: 0.00618 | Acc: 0.99851 | macro_f1 0.99816 | micro_f1 0.99851 | recall 0.99851 | precision 0.99851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.00618 | Acc: 0.99851 | macro_f1 0.99816 | micro_f1 0.99851 | recall 0.99851 | precision 0.99851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 94/168 [05:12<04:13,  3.42s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      " 70%|███████   | 118/168 [06:51<03:54,  4.69s/it]c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "100%|██████████| 168/168 [09:42<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0005\n",
      "Train: Loss: 0.02351 | Acc: 0.99104 | macro_f1 0.98867 | micro_f1 0.99104 | recall 0.99104 | precision 0.99104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\TiffImagePlugin.py:868: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "c:\\Users\\bebed\\anaconda3\\envs\\bigdataenv\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Loss: 0.02350 | Acc: 0.99104 | macro_f1 0.98867 | micro_f1 0.99104 | recall 0.99104 | precision 0.99104\n"
     ]
    }
   ],
   "source": [
    "for i_epoch in range(start_epoch, max_epochs):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        loss, _, _ = model_forward(i_epoch, model, criterion, batch)\n",
    "        loss = loss / 24\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        global_step += 1\n",
    "        if global_step % 24 == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    print(\"Train Loss: {:.4f}\".format(np.mean(train_losses)))\n",
    "    metrics = model_eval(i_epoch, train_loader, model, criterion)\n",
    "    print(\"{}: Loss: {:.5f} | Acc: {:.5f} | macro_f1 {:.5f} | micro_f1 {:.5f} | recall {:.5f} | precision {:.5f}\".format(\n",
    "                \"Train\", metrics[\"loss\"], metrics[\"acc\"], metrics[\"macro_f1\"], metrics[\"micro_f1\"], metrics[\"recall\"],  metrics[\"precision\"]))\n",
    "    \n",
    "    tuning_metric = (metrics[\"acc\"])\n",
    "    scheduler.step(tuning_metric)\n",
    "    is_improvement = tuning_metric > best_metric\n",
    "    if is_improvement:\n",
    "        best_metric = tuning_metric\n",
    "        n_no_improve = 0\n",
    "    else:\n",
    "        n_no_improve += 1\n",
    "    \n",
    "    model.eval()\n",
    "    test_metrics = model_eval(\n",
    "        np.inf, test_loader, model, criterion\n",
    "    )\n",
    "    print(\"{}: Loss: {:.5f} | Acc: {:.5f} | macro_f1 {:.5f} | micro_f1 {:.5f} | recall {:.5f} | precision {:.5f}\".format(\n",
    "                \"Test\", test_metrics[\"loss\"], test_metrics[\"acc\"], test_metrics[\"macro_f1\"], test_metrics[\"micro_f1\"], test_metrics[\"recall\"], test_metrics[\"precision\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model\n",
    "# del optimizer\n",
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdataenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
